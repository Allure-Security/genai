{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Building up to an agent\n",
        "LLM -> Chain -> Agent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Data cleaning exmaple"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'pydantic.v1'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32m/Users/rodrigoceballoslentini/repos/georgian/genai-bootcamp/notebooks/day-2/03-agents-and-toolkits.ipynb Cell 3\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rodrigoceballoslentini/repos/georgian/genai-bootcamp/notebooks/day-2/03-agents-and-toolkits.ipynb#W2sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39magents\u001b[39;00m \u001b[39mimport\u001b[39;00m initialize_agent\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rodrigoceballoslentini/repos/georgian/genai-bootcamp/notebooks/day-2/03-agents-and-toolkits.ipynb#W2sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39magents\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39magent_types\u001b[39;00m \u001b[39mimport\u001b[39;00m AgentType\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/rodrigoceballoslentini/repos/georgian/genai-bootcamp/notebooks/day-2/03-agents-and-toolkits.ipynb#W2sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpydantic\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv1\u001b[39;00m \u001b[39mimport\u001b[39;00m BaseModel, Field\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rodrigoceballoslentini/repos/georgian/genai-bootcamp/notebooks/day-2/03-agents-and-toolkits.ipynb#W2sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mDataCleaningInput\u001b[39;00m(BaseModel):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rodrigoceballoslentini/repos/georgian/genai-bootcamp/notebooks/day-2/03-agents-and-toolkits.ipynb#W2sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m     data: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m Field()\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pydantic.v1'"
          ]
        }
      ],
      "source": [
        "from langchain.chains import LLMChain, SequentialChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('../extra_resources/candy-data.csv')\n",
        "\n",
        "llm = ChatOpenAI(\n",
        "    model_name='gpt-3.5-turbo',\n",
        "    temperature=0,\n",
        ")\n",
        "\n",
        "# Chain\n",
        "prompt = PromptTemplate.from_template(\"Remove missing values from this data: {data}\")\n",
        "remove_missing_values_chain = LLMChain(llm=llm, prompt=prompt, output_key=\"cleaned_data\")\n",
        "\n",
        "prompt = PromptTemplate.from_template(\"Normalize this numerical data: {data}\")\n",
        "normalize_data_chain = LLMChain(llm=llm, prompt=prompt, output_key=\"normalized_data\")\n",
        "\n",
        "prompt = PromptTemplate.from_template(\"Encode these categorical variables: {data}\")\n",
        "encode_categorical_chain = LLMChain(llm=llm, prompt=prompt, output_key=\"encoded_data\")\n",
        "\n",
        "data_cleaning_chain = SequentialChain(\n",
        "    chains=[remove_missing_values_chain, normalize_data_chain, encode_categorical_chain],\n",
        "    input_variables=[\"data\"],\n",
        "    output_variables=[\"cleaned_data\", \"normalized_data\", \"encoded_data\"],\n",
        "    verbose=True)\n",
        "\n",
        "\n",
        "# Agent\n",
        "from langchain.tools import Tool\n",
        "from langchain.agents import initialize_agent\n",
        "from langchain.agents.agent_types import AgentType\n",
        "from pydantic.v1 import BaseModel, Field\n",
        "\n",
        "class DataCleaningInput(BaseModel):\n",
        "    data: str = Field()\n",
        "\n",
        "remove_missing_values_tool = Tool.from_function(\n",
        "    func=remove_missing_values_chain.run,\n",
        "    name=\"Remove Missing Values\",\n",
        "    description=\"Removes missing values from the data.\",\n",
        "    args_schema=DataCleaningInput\n",
        ")\n",
        "\n",
        "normalize_data_tool = Tool.from_function(\n",
        "    func=normalize_data_chain.run,\n",
        "    name=\"Normalize Data\",\n",
        "    description=\"Normalizes numerical data.\",\n",
        "    args_schema=DataCleaningInput\n",
        ")\n",
        "\n",
        "encode_categorical_tool = Tool.from_function(\n",
        "    func=encode_categorical_chain.run,\n",
        "    name=\"Encode Categorical Variables\",\n",
        "    description=\"Encodes categorical variables into numerical format.\",\n",
        "    args_schema=DataCleaningInput\n",
        ")\n",
        "\n",
        "tools = [remove_missing_values_tool, normalize_data_tool, encode_categorical_tool]\n",
        "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'pydantic.v1'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32m/Users/rodrigoceballoslentini/repos/georgian/genai-bootcamp/notebooks/day-2/02-agents-and-toolkits.ipynb Cell 4\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rodrigoceballoslentini/repos/georgian/genai-bootcamp/notebooks/day-2/02-agents-and-toolkits.ipynb#X16sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39magents\u001b[39;00m \u001b[39mimport\u001b[39;00m initialize_agent\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rodrigoceballoslentini/repos/georgian/genai-bootcamp/notebooks/day-2/02-agents-and-toolkits.ipynb#X16sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39magents\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39magent_types\u001b[39;00m \u001b[39mimport\u001b[39;00m AgentType\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/rodrigoceballoslentini/repos/georgian/genai-bootcamp/notebooks/day-2/02-agents-and-toolkits.ipynb#X16sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpydantic\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv1\u001b[39;00m \u001b[39mimport\u001b[39;00m BaseModel, Field\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rodrigoceballoslentini/repos/georgian/genai-bootcamp/notebooks/day-2/02-agents-and-toolkits.ipynb#X16sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mDataCleaningInput\u001b[39;00m(BaseModel):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rodrigoceballoslentini/repos/georgian/genai-bootcamp/notebooks/day-2/02-agents-and-toolkits.ipynb#X16sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     data: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m Field()\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pydantic.v1'"
          ]
        }
      ],
      "source": [
        "# Agent\n",
        "from langchain.tools import Tool\n",
        "from langchain.agents import initialize_agent\n",
        "from langchain.agents.agent_types import AgentType\n",
        "from pydantic.v1 import BaseModel, Field\n",
        "\n",
        "class DataCleaningInput(BaseModel):\n",
        "    data: str = Field()\n",
        "\n",
        "remove_missing_values_tool = Tool.from_function(\n",
        "    func=remove_missing_values_chain.run,\n",
        "    name=\"Remove Missing Values\",\n",
        "    description=\"Removes missing values from the data.\",\n",
        "    args_schema=DataCleaningInput\n",
        ")\n",
        "\n",
        "normalize_data_tool = Tool.from_function(\n",
        "    func=normalize_data_chain.run,\n",
        "    name=\"Normalize Data\",\n",
        "    description=\"Normalizes numerical data.\",\n",
        "    args_schema=DataCleaningInput\n",
        ")\n",
        "\n",
        "encode_categorical_tool = Tool.from_function(\n",
        "    func=encode_categorical_chain.run,\n",
        "    name=\"Encode Categorical Variables\",\n",
        "    description=\"Encodes categorical variables into numerical format.\",\n",
        "    args_schema=DataCleaningInput\n",
        ")\n",
        "\n",
        "tools = [remove_missing_values_tool, normalize_data_tool, encode_categorical_tool]\n",
        "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Agents\n",
        "\n",
        "There are many types of agent that work in slightly different ways, but the main concepts behind an agent are:\n",
        "\n",
        "1. The agent has access to tools. Tools include instructions on how to use them and what they are useful for. A tool can be anything that could be used by using text.\n",
        "2. The agent has a task, usually this is just the prompt from the user.\n",
        "3. The agent has access to an LLM and a system prompt that tells it how to go about achieving its task given its tools\n",
        "4. The agent will attempt to break down its task according to its programming and iteratively take steps to achieve it. The agent will try to use the tools at its disposal when it makes sense and (usually) will eventually decide it is done and return a final output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.agents.agent_toolkits import create_python_agent\n",
        "from langchain.tools.python.tool import PythonREPLTool\n",
        "from langchain.python import PythonREPL\n",
        "from langchain.llms.openai import OpenAI\n",
        "from langchain.agents.agent_types import AgentType\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from pandasai import SmartDataframe\n",
        "import pandas as pd\n",
        "from langchain.tools import BaseTool, StructuredTool, Tool, tool\n",
        "\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "\n",
        "class FaultTolerantSmartDataframe:\n",
        "    def __init__(self, df, config):\n",
        "        self.sdf = SmartDataframe(df, config=config)\n",
        "    \n",
        "    def __call__(self, prompt):\n",
        "        try:\n",
        "            return self.sdf.chat(prompt)\n",
        "        except Exception as e:\n",
        "            return f'Error: {e}'\n",
        "        \n",
        "\n",
        "llm = ChatOpenAI(\n",
        "    model_name='gpt-4',\n",
        "    temperature=0,\n",
        ")\n",
        "df = pd.read_csv('../extra_resources/candy-data.csv')\n",
        "sdf = FaultTolerantSmartDataframe(df, config={\"llm\": llm})\n",
        "\n",
        "tools = ClickupToolkit().tools\n",
        "    \n",
        "candy_data_tool = Tool.from_function(\n",
        "    func=sdf,\n",
        "    name=\"Smart Candy Dataset\",\n",
        "    description=\"Useful to get general information about candies, their classification, price, price and rating. You can ask it questions in natural language and it will answer back.\",\n",
        "    # args_schema=CodeSuggestionsInput\n",
        ")\n",
        "\n",
        "from langchain.agents import initialize_agent\n",
        "\n",
        "model = ChatOpenAI(temperature=0)\n",
        "tools = [candy_data_tool, PythonREPLTool()]\n",
        "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "from langchain.agents import initialize_agent\n",
        "\n",
        "model = ChatOpenAI(temperature=0)\n",
        "tools = [candy_data_tool, PythonREPLTool()]\n",
        "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new  chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mFirst, I need to know what the categories are. Then, I can find candies that cover multiple categories and try to find the minimum set.\n",
            "Action: Smart Candy Dataset\n",
            "Action Input: What are the candy categories?\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mchocolate, fruity, caramel, peanutyalmondy, nougat, crispedricewafer, hard, bar, pluribus\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mNow that I know the categories, I need to find candies that cover multiple categories. I'll start by finding candies that cover the most categories.\n",
            "Action: Smart Candy Dataset\n",
            "Action Input: Which candies cover the most categories?\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mThe candies that cover the most categories are: Baby Ruth, Snickers, Snickers Crisper.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mNow I know which candies cover the most categories. I need to check which categories are covered by these candies.\n",
            "Action: Smart Candy Dataset\n",
            "Action Input: Which categories are covered by Baby Ruth, Snickers, and Snickers Crisper?\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m      competitorname  chocolate  fruity  caramel  peanutyalmondy  nougat  \\\n",
            "6          Baby Ruth          1       0        1               1       1   \n",
            "64          Snickers          1       0        1               1       1   \n",
            "65  Snickers Crisper          1       0        1               1       0   \n",
            "\n",
            "    crispedricewafer  hard  bar  pluribus  sugarpercent  pricepercent  \\\n",
            "6                  0     0    1         0         0.604         0.767   \n",
            "64                 0     0    1         0         0.546         0.651   \n",
            "65                 1     0    1         0         0.604         0.651   \n",
            "\n",
            "    winpercent  \n",
            "6    56.914547  \n",
            "64   76.673782  \n",
            "65   59.529251  \u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mBaby Ruth and Snickers cover the same categories: chocolate, caramel, peanutyalmondy, nougat, and bar. Snickers Crisper covers an additional category: crispedricewafer. The remaining categories are fruity, hard, and pluribus. I need to find candies that cover these remaining categories.\n",
            "Action: Smart Candy Dataset\n",
            "Action Input: Which candies cover the categories fruity, hard, and pluribus?\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m         competitorname  chocolate  fruity  caramel  peanutyalmondy  nougat  \\\n",
            "17           Gobstopper          0       1        0               0       0   \n",
            "26           Jawbusters          0       1        0               0       0   \n",
            "41                Nerds          0       1        0               0       0   \n",
            "49            Pop Rocks          0       1        0               0       0   \n",
            "58                Runts          0       1        0               0       0   \n",
            "63       Smarties candy          0       1        0               0       0   \n",
            "69  Strawberry bon bons          0       1        0               0       0   \n",
            "\n",
            "    crispedricewafer  hard  bar  pluribus  sugarpercent  pricepercent  \\\n",
            "17                 0     1    0         1         0.906         0.453   \n",
            "26                 0     1    0         1         0.093         0.511   \n",
            "41                 0     1    0         1         0.848         0.325   \n",
            "49                 0     1    0         1         0.604         0.837   \n",
            "58                 0     1    0         1         0.872         0.279   \n",
            "63                 0     1    0         1         0.267         0.116   \n",
            "69                 0     1    0         1         0.569         0.058   \n",
            "\n",
            "    winpercent  \n",
            "17   46.783348  \n",
            "26   28.127439  \n",
            "41   55.354046  \n",
            "49   41.265511  \n",
            "58   42.849144  \n",
            "63   45.995827  \n",
            "69   34.578991  \u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mThere are several candies that cover the remaining categories: fruity, hard, and pluribus. I can choose any of them. So, the minimum combination of candies that together include all categories are Snickers Crisper and any one of the candies that cover the remaining categories.\n",
            "Final Answer: The minimum combination of candies that together include all categories are Snickers Crisper and any one of the candies that cover the remaining categories: Gobstopper, Jawbusters, Nerds, Pop Rocks, Runts, Smarties candy, or Strawberry bon bons.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'The minimum combination of candies that together include all categories are Snickers Crisper and any one of the candies that cover the remaining categories: Gobstopper, Jawbusters, Nerds, Pop Rocks, Runts, Smarties candy, or Strawberry bon bons.'"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent.run('What is the minimum combination of candies that together include all categories? Remember there are many candies that can cover multiple categories. Show me evidence this is indeed the minimum set.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# [Toolkits](https://python.langchain.com/docs/modules/agents/toolkits/)\n",
        "### [Document Comparisons](https://python.langchain.com/docs/integrations/toolkits/document_comparison_toolkit)\n",
        "- Tool that wraps full documents. This is an easy way to do document QA on a short list of documents.\n",
        "- Includes PDF reader.\n",
        "### [Vectorstore](https://python.langchain.com/docs/integrations/toolkits/vectorstore)\n",
        "- Interface with arbitrary vector store\n",
        "### [JSON](https://python.langchain.com/docs/integrations/toolkits/json)\n",
        "- Tool for interacting with large JSON/dict objects.\n",
        "### [OpenAPI](https://python.langchain.com/docs/integrations/toolkits/openapi)\n",
        "- Tool to consume arbitrary APIs, here APIs conformant to the OpenAPI/Swagger specification.\n",
        "### [Natural Language APIs](https://python.langchain.com/docs/integrations/toolkits/openapi_nla)\n",
        "- efficiently plan and combine calls across endpoints using natural language as an intermediary\n",
        "### Specific Services\n",
        "- [Github](https://python.langchain.com/docs/integrations/toolkits/github)\n",
        "- [Office 365](https://python.langchain.com/docs/integrations/toolkits/office365)\n",
        "- [ClickUp - (WIP / georgian made.)](https://github.com/langchain-ai/langchain/pull/10662)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['AWS_ACCESS_KEY_ID']=\"AKIA37K4OWT5C66WM2V2\"\n",
        "os.environ['AWS_SECRET_ACCESS_KEY']=\"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\"\n",
        "os.environ['AWS_DEFAULT_REGION']=\"us-east-1\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Here is how I would explain cats to 8th grade students:\n",
            "\n",
            "Cats are small, furry mammals that are kept as pets by many people. There are over 70 different breeds of domestic cats. Some common cat breeds include Siamese, Persian, Maine Coon, and tabby cats. \n",
            "\n",
            "Cats have several unique features that help them survive as predators:\n",
            "\n",
            "- Retractable claws - Cats can extend and retract their sharp claws to help them climb, hunt prey, and defend themselves. Their claws are attached to the last bone of each toe.\n",
            "\n",
            "- Whiskers - The long, stiff hairs on a cat's face are called whiskers. They help cats detect objects and navigate in the dark. \n",
            "\n",
            "- Excellent night vision - Cats can see well in dim light thanks to extra reflecting cells in their eyes called the tapetum lucidum. This layer helps them hunt at night.\n",
            "\n",
            "- Flexible bodies - Cats are extremely agile. They can twist, jump, climb, and squeeze through very small spaces thanks to their flexible spines. This helps them climb trees and hunt prey.\n",
            "\n",
            "- Jacobson's organ - Cats have an extra smelling ability thanks to the Jacobson's organ in the roof of their mouth. It detects pheromones and helps trigger behaviors like mating.\n",
            "\n",
            "Cats sleep 12-16 hours per day on average. They are crepuscular, which\n"
          ]
        }
      ],
      "source": [
        "import boto3\n",
        "import json\n",
        "bedrock = boto3.client(service_name='bedrock-runtime')\n",
        "\n",
        "body = json.dumps({\n",
        "    \"prompt\": \"\\n\\nHuman:explain cats to 8th graders\\n\\nAssistant:\",\n",
        "    \"max_tokens_to_sample\": 300,\n",
        "    \"temperature\": 0.1,\n",
        "    \"top_p\": 0.9,\n",
        "})\n",
        "\n",
        "modelId = 'anthropic.claude-v2'\n",
        "accept = 'application/json'\n",
        "contentType = 'application/json'\n",
        "\n",
        "response = bedrock.invoke_model(body=body, modelId=modelId, accept=accept, contentType=contentType)\n",
        "\n",
        "response_body = json.loads(response.get('body').read())\n",
        "print(response_body.get('completion'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "genai-bootcamp",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 2
}