{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 1 - Function Calling\n",
    "\n",
    "In this notebook, we explore the function calling feature offered by OpenAI's GPT models. While the name sounds pretty fancy, in essence, given the definition of a number of functions, the LLM can decide which function to call and return a JSON object that matches the required parameters. This functionality is achieved through finetuning. Note that while the model returns the parameters for the function call, the function itself is not called by the model. The user must manually call the function or utilize this API as part of a larger system.\n",
    "\n",
    "You can read more about this function calling capability [here](https://platform.openai.com/docs/guides/gpt/function-calling).\n",
    "\n",
    "Note: Since this is an OpenAI-specific functionality, we do not use the universal `llm_call` from previous notebooks. Instead, we directly use the OpenAI API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load environment variables\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"../../.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example dummy function hard coded to return the same weather\n",
    "# In production, this could be your backend API or an external API\n",
    "def get_current_weather(location, unit=\"celsius\"):\n",
    "    \"\"\"Get the current weather in a given location\"\"\"\n",
    "    weather_info = {\n",
    "        \"location\": location,\n",
    "        \"temperature\": \"18\",\n",
    "        \"unit\": unit,\n",
    "        \"forecast\": [\"sunny\", \"windy\"],\n",
    "    }\n",
    "    return json.dumps(weather_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_conversation(message):\n",
    "    # Step 1: send the conversation and available functions to GPT\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful chat assistant. Only use the functions you have been provided with.\"},\n",
    "        {\"role\": \"user\", \"content\": message}\n",
    "    ]\n",
    "    functions = [\n",
    "        {\n",
    "            \"name\": \"get_current_weather\",\n",
    "            \"description\": \"Get the current weather in a given location\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                    },\n",
    "                    \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
    "                },\n",
    "                \"required\": [\"location\"],\n",
    "            },\n",
    "        }\n",
    "    ]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=messages,\n",
    "        functions=functions,\n",
    "        function_call=\"auto\",  # auto is default, but we'll be explicit\n",
    "    )\n",
    "    response_message = response[\"choices\"][0][\"message\"]\n",
    "    # Step 2: check if GPT wanted to call a function\n",
    "    if response_message.get(\"function_call\"):\n",
    "        # Step 3: call the function\n",
    "        # Note: the JSON response may not always be valid; be sure to handle errors\n",
    "        available_functions = {\n",
    "            \"get_current_weather\": get_current_weather,\n",
    "        }  # only one function in this example, but you can have multiple\n",
    "        function_name = response_message[\"function_call\"][\"name\"]\n",
    "        function_to_call = available_functions[function_name]\n",
    "        function_args = json.loads(response_message[\"function_call\"][\"arguments\"])\n",
    "        function_response = function_to_call(\n",
    "            location=function_args.get(\"location\"),\n",
    "            unit=function_args.get(\"unit\"),\n",
    "        )\n",
    "\n",
    "        # Step 4: send the info on the function call and function response to GPT\n",
    "        messages.append(response_message)  # extend conversation with assistant's reply\n",
    "        messages.append(\n",
    "            {\n",
    "                \"role\": \"function\",\n",
    "                \"name\": function_name,\n",
    "                \"content\": function_response,\n",
    "            }\n",
    "        )  # extend conversation with function response\n",
    "        second_response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=messages,\n",
    "        )  # get a new response from GPT where it can see the function response\n",
    "        return second_response[\"choices\"][0][\"message\"][\"content\"]\n",
    "    else:\n",
    "        return response_message[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weather in Toronto is currently 18Â°C, sunny, and windy.\n"
     ]
    }
   ],
   "source": [
    "# Model detects that we need to make a function call here\n",
    "print(run_conversation(\"What's the weather like in Toronto?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best time to visit Banff, Canada, largely depends on the activities you're interested in. \n",
      "\n",
      "Summer (June to August) is a great time for hiking, wildlife viewing, and mountain biking. It's the busiest time of year, so you'll need to book accommodation and activities far in advance.\n",
      "\n",
      "The winter season (December to March) offers excellent conditions for skiing, snowboarding, and other winter sports. Banff's three ski areas - Mount Norquay, Sunshine Village, and Lake Louise - usually have good snow conditions throughout the season.\n",
      "\n",
      "Fall (September to November) can be a more peaceful time to visit, with fewer crowds. The weather can be unpredictable, so be prepared for various conditions. \n",
      "\n",
      "Spring (April to May) is a transition period with both winter snow and warmer days. Good for those looking for quieter times and considered off-peak.  \n",
      "\n",
      "Keep in mind that mountain weather can be unpredictable, so it's always a good idea to check the current weather before you head out.\n"
     ]
    }
   ],
   "source": [
    "# Model doesn't make any function calls here\n",
    "print(run_conversation(\"When is the best time to visit Banff?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "While the above example appears relatively simple, it demonstrates how we can use function calling in more powerful ways. It converts natural language queries into a structured function call which can then be called and returned directly or used in further downstream systems. You can find a more detailed example [in the OpenAI Cookbook](https://cookbook.openai.com/examples/how_to_call_functions_with_chat_models)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai-bootcamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
